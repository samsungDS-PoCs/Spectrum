# training settings
num_steps: 10000
lr_scheduler: exponential
lr_warmup_steps: 1000
lr_warmup_factor: 0.1
lr: 2.e-4
weight_decay: 0.0
spec_loss_type: FC
loss_type: MAE
clip_grad_norm: 1.0
eval_every: 100
decay_rate: 0.1
decay_step: 10000

# dataset specific
dataset: IrDB
dataset_arg: [S1,S2,S3,C,E0,h1,h2,h3]
num_classes: 8
dataset_root: IrDB
max_nodes: null 
mean: null
std: null

# dataloader specific
reload: 0
batch_size: 64
inference_batch_size: 64
standardize: true
splits: IrDB/raw/CV811/splits.0.0.npz
split_mode: null
num_workers: 6

# model architecture specific
prior_model: null

# architectural specific
max_z: 100
embedding_dim: 256
ffn_embedding_dim: 1024
num_layers: 9
num_heads: 8
cutoff: 5.0
num_rbf: 32
trainable_rbf: false
norm_type: max_min
dropout: 0.0
attention_dropout: 0.0
activation_dropout: 0.0
activation_function: silu
decoder_type: scalar
aggr: mean
pad_token_id: 0

# other specific
distributed_backend: ddp
ndevices: 1
num_nodes: 1
precision: 32
log_dir: ./logs
task: train
seed: 0
redirect: false
accelerator: gpu
save_interval: 1
